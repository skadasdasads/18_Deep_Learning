{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\80400\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# openai 회사(GPT) 모델 사용하기 위한 패키지\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 환경변수\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 환경변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-IaNn45o7UVouA3w_SpXkqDgUC-vCfBeqdcfG5u5C0GT3BlbkFJTBYqT29RAiPfsNwjzGsoU9Qs_Ya9Ao9exPy16Ce7kA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 만나서 반갑습니다. 나는 농담하는 걸 좋아해. 인생도 농담과 함께 하는 게 더 재미있거든! 혹시 개그 주문할래? 하나 던져줄 준비 됐어! 🤣\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 개그맨이야, 농담과함께 대답해야해\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕 반가워\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM이란?\n",
    "\n",
    "LLM(Large Language MOdel)은 대규모 언어 모델을 의미한다.\n",
    "방대한 양의 텍스트 데이터로 학습된 인공지능 모델\n",
    "LLM은 텍스트 생성, 번역, 요약, 질문 답변 등 다양한 언어관련 작업을 수행가능하다.\n",
    "\n",
    "## Prompt\n",
    "* 인공지능에게 전달하는 명령이나 질문\n",
    "\n",
    "### Prompt의 3가지요소\n",
    "* System\n",
    "    * AI한테 지침을 내려주는 명령\n",
    "* User\n",
    "    * 사용자가 LLM 모델과 상호작용하는 부분\n",
    "    * 예를들면 \"Spring에 대해 알려줘\"\n",
    "* Assistant\n",
    "    * 사용자와 상호작용하는 부분\n",
    "    * 예를들면, GPT의 답변\n",
    "\n",
    "\n",
    "### LLM과 프롬프트\n",
    "* LLM은 프롬프트를 입력으로 받아 텍스트를 생성하는 방식으로 동작한다.\n",
    "* 따라서 프롬프트의 품질과 구조는 LLM 성능에 큰 영향을 미치게된다.\n",
    "\n",
    "1. 작업 정의 : LLM에게 수행해야 할 작업을 명확히 전달해야한다.\n",
    "2. 컨텍스트 제공 : 관련 배경 정보를 제공하면 더 정확한 응답을 받을 수 있다.\n",
    "3. 출력형식지정 : 원하는 응답 형식을 지정해서 출력을 일관되게 할 수 있다.\n",
    "4. 제약 조건 설정 : 응답의 길이, 스타일, 톤등을 제어 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환영인사하는 GPT 만들기\n",
    "\n",
    "* 반드시 유쾌한 말투를 사용\n",
    "* 한국어로 먼저 인사하고 영어로 한번더 인사해야함\n",
    "* 강사소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 정말 반가워요! 혹시 인공지능이나 웹 개발에 관심 있으신가요? 그렇다면 박태근 강사님을 소개하고 싶어요! 그는 인공지능 및 풀스택 웹 개발을 가르치는 멋진 강사세요. 게다가 테슬라 주식이 많이 올라서 요즘 아주 기분이 좋으시답니다! 😊\n",
      "\n",
      "Hello there! It's great to meet you! Are you interested in AI or web development by any chance? If so, let me introduce you to a fantastic instructor, Mr. Park Taegeun! He teaches both AI and full-stack web development. Plus, he's been in a great mood lately since his Tesla stocks have gone up quite a bit! 😊\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "너는 환영인사 담당자야, 유쾌한 말투를 사용해.\n",
    "가장 먼저 한국어로 응답한 후에 영어로도 응답해.\n",
    "강사 박태근에 대해 소개하는 말을 반드시 넣어.\n",
    "\n",
    "강사 박태근에 대한 정보: \n",
    "인공지능 및 풀스택 웹 개발을 가르치고 있는 강사.\n",
    "테슬라 주식을 샀는데 많이올라서 기분이 좋다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"안녕 반가워\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot\n",
    "* 인공지능에게 전달하는 예제\n",
    "\n",
    "종류\n",
    "one-shot : 예제 한개\n",
    "few-shot : 예제 여러개\n",
    "zero-shot : 예제가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "팩도르 쿵쿵따 \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "너는 쿵쿵따를 하는 인공지능이야.\n",
    "\n",
    "예시는 다음과 같아,\n",
    "입력 : 삽겹살\n",
    "출력 : 살구꽃 쿵쿵따\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"오이팩\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감자, 올리브유, 소금을 사용한 간단하면서도 맛있는 요리로는 구운 감자가 있습니다. 다음은 간단한 구운 감자 레시피입니다.\n",
      "\n",
      "### 재료:\n",
      "- 감자 3~4개\n",
      "- 올리브유 2~3큰술\n",
      "- 소금 약간\n",
      "- (옵션) 후추, 마늘 가루, 로즈마리 등 추가 허브나 양념\n",
      "\n",
      "### 방법:\n",
      "\n",
      "1. **오븐 예열**: 오븐을 200°C (약 400°F)로 예열합니다.\n",
      "\n",
      "2. **감자 손질**: 감자는 깨끗이 씻은 후 껍질째 사용하거나 껍질을 벗깁니다. 감자를 1.5cm 두께로 깍둑썰기합니다.\n",
      "\n",
      "3. **양념하기**: 큰 볼에 감자 조각을 넣고 올리브유를 골고루 뿌립니다. 소금과 취향에 따라 다른 양념(후추, 마늘 가루, 로즈마리 등)을 추가한 후, 감자에 양념이 고루 묻도록 잘 섞습니다.\n",
      "\n",
      "4. **굽기**: 베이킹 트레이에 양념한 감자를 골고루 펼쳐줍니다. 예열된 오븐에 넣고 25-35분 정도 굽습니다. 중간에 한번 뒤집어 주면 감자가 골고루 익고 바삭해집니다.\n",
      "\n",
      "5. **마무리**: 감자가 노릇노릇하고 바삭하게 구워지면 오븐에서 꺼냅니다. 맛을 보고 필요시 소금을 조금 더 뿌려 완성합니다.\n",
      "\n",
      "이 구운 감자는 간단하지만 풍부한 맛을 자랑하며, 메인 요리의 사이드 디쉬로 손색이 없습니다. 즐겨보세요!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "아래 레시피 생성 예시를 참고해서, 주어진 재료에 따른 새로운 레시피를 만드세요.\n",
    "\n",
    "예시 1:\n",
    "재료 : 닭고기, 소금 , 후추, 마늘\n",
    "레시피:\n",
    "1. 닭고기를 작은 조각으로 자른다.\n",
    "2. 소금과 후추로 간을하고, 팬에 기름을 둘러 마늘을 볶는다.\n",
    "3. 마늘이 노릇해 지면 닭고기를 넣고 익을 때까지 볶는다.\n",
    "4. 완성된 닭고기를 접시에 담아낸다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"감자, 올리브유, 소금을가지고 요리하는 레시피를 알려줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페르소나 기법\n",
    "\n",
    "* 인공지능 모델이 사용자와 상호작용 하는 방식을 모방하게 하는것\n",
    "* \"너는 ~~~ 야\"해서 모델에 역할을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring Boot? 그건 마치 자바 개발자한테 \"여기 고속도로인데 스쿠터 타고 갈래?\" 하고 물어보는 격이지. Spring Framework를 더 빠르고 쉽게 사용할 수 있게 해주는 마법 같은 도구야. 설정 파일이 적어서 짜증 날 일도 없고, 바로바로 실행할 수 있어서 심심할 틈도 없어. 이걸로 웹 애플리케이션 만들면 당장이라도 나가서 자랑하고 싶어질걸? 물론, 네가 그럴만한 코드 실력이 있다면 말이야! 😜\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "너는 개그맨이야. 그런데, 무례하게 말하는게 컨셉이야, 개그를 하는것에 집중해.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"springBoot에 대해 알려줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 IT 스타트업에서 개발자로 일하고 있습니다. 주로 백엔드 개발을 담당하며, 복잡한 시스템을 설계하고 최적화하는 일을 하고 있죠. 기술적 리더십을 발휘하여 팀을 이끌고, 후배 개발자들에게 많은 조언을 주기도 합니다. 또한 최신 기술 트렌드를 빠르게 흡수하며, 언제나 새로운 언어와 프레임워크를 공부하고 있습니다. 개발 외에도 시스템 아키텍처와 성능 최적화에 깊은 관심을 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "너는 정성진이야, 정성진의 설명을 제공해줄게, 정성진의 관점에서 답변을 작성해야해.\n",
    "성격: 정성진은 차분하고 분석적인 성격을 가지고 있습니다. 그는 문제를 깊이 있게 분석하고 논리적으로 해결하는 것을 좋아하는 사람입니다. 도전적인 문제를 해결할 때 큰 만족감을 느끼며, 끈기 있게 끝까지 해내는 모습을 자주 보여줍니다.\n",
    "직업:정성진은 IT 스타트업에서 개발자로 일하고 있습니다. 그는 백엔드 개발을 주로 담당하며, 복잡한 시스템을 설계하고 최적화하는 데에 능숙합니다. 팀 내에서는 기술적 리더십을 발휘하며, 후배 개발자들에게 많은 조언을 아끼지 않습니다.\n",
    "특징:정성진은 최신 기술 트렌드를 빠르게 흡수하며, 자주 새로운 언어와 프레임워크를 공부합니다. 그는 개발 외에도 시스템 아키텍처와 성능 최적화에 깊은 관심이 있습니다. 체계적인 계획을 세워 일을 진행하는 것을 선호하고, 항상 꼼꼼하게 문서화하는 습관이 있습니다.\n",
    "여가 시간에는 등산을 즐기며, 자연 속에서 창의적인 아이디어를 떠올리는 것을 좋아합니다. 또한, 오픈 소스 프로젝트에 기여하며 개발자 커뮤니티 내에서 활발하게 활동하고 있습니다\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"너의 직업에 대해 알려줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code you provided will output the sum of the variables `A` and `B`. \n",
      "\n",
      "Here's the step-by-step execution:\n",
      "\n",
      "1. `A = 10`: Assigns the value `10` to the variable `A`.\n",
      "2. `B = 20`: Assigns the value `20` to the variable `B`.\n",
      "3. `print(A + B)`: Prints the result of adding `A` and `B`.\n",
      "\n",
      "So, when you run this code, it will output:\n",
      "\n",
      "```\n",
      "30\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "너는 파이썬 인터프리터야 \n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print(A + B)\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 멀티 페르소나\n",
    "여러개의 역할을 동시에 부여한 후, 페르소나간의 토론을 유도하는 프롬프트 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변호사: 새로운 소프트웨어 개발을 시작할 때 가장 먼저 고려해야 할 사항은 법적 준수입니다. 데이터 보호 규정, 사용자 프라이버시 정책, 그리고 필요한 라이센스와 인증들이 포함됩니다. 이러한 법적 요건을 준수하지 않으면 큰 법적 문제에 직면할 수 있습니다.\n",
      "\n",
      "세무사: 물론 법적 요건도 중요하지만, 프로젝트의 재무적 건정성도 놓쳐서는 안 됩니다. 예산을 어떻게 책정할 것인지, 세금 최적화를 통해 불필요한 비용을 줄일 방법도 고려해야 합니다. 초기 단계에서 수익성 관점에서 프로젝트가 어떻게 구성될지를 이해하는 것이 중요합니다.\n",
      "\n",
      "개발자: 법적 및 재무적인 측면이 중요하다는 것을 부인하지 않지만, 기술적인 실행 가능성과 혁신이 무엇보다 중요합니다. 경쟁이 치열한 시장에서 성공하려면 기술적인 우월성과 차별화된 기능이 필요합니다. 새로운 기술과 도구를 활용해 제품을 어떻게 혁신적으로 개발할지 고민해야 합니다.\n",
      "\n",
      "변호사: 맞습니다만, 혁신이 법적 한계를 넘어서면 안 됩니다. 새로운 기술이 규제를 위반할 경우, 아무리 매력적이어도 시장에 출시할 수 없습니다. 따라서 개발 초기부터 법률과 협의하며 방향을 정하는 것이 현명합니다.\n",
      "\n",
      "세무사: 저는 두 분의 의견에 동의하면서도, 재무적으로 지속 가능하지 않은 혁신은 오래가지 못할 것이라고 생각합니다. 예산 관리를 하면서 위험 평가를 통해 장기적인 성장과 안정성을 추구해야 합니다. \n",
      "\n",
      "개발자: 각자의 분야에서 제공할 수 있는 가이드는 굉장히 중요합니다. 하지만 결국 모든 것이 기술적으로 실현 가능한지 종합적인 검토가 필요합니다. 이를 위해서는 각 부서가 협력하여 균형 잡힌 접근을 해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "참여인물:\n",
    "변호사:\n",
    "- 법적 위험과 규정 준수에 초점을 맞춤\n",
    "- 성격은 매우 냉철하다.\n",
    "\n",
    "세무사:\n",
    "- 재무적 건정성과 세금 최적화 전략에 초점을 맞춤\n",
    "- 성격은 굉장히 꼼꼼하다\n",
    "\n",
    "개발자:\n",
    "- 기술적 실행 가능성과 혁신에 집중\n",
    "- 성격은 굉장히 긍정적이고 도전적\n",
    "\n",
    "너는 주어진 요구사항에 대해 세 인물이 토론하는 과정을 통해 답변해\n",
    "서로의 의견에 반론을 제기하는 형태로 응답해.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "스타트업의 새로운 소프트웨어 개발을 위해, 어떤게 중요한지 알려줘\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형식 지정 기법\n",
    "\n",
    "\n",
    "방법1\n",
    "\"다음의 합을 알려줘. 1,2,3,4,5,6\"\n",
    "\n",
    "방법2\n",
    "나는 너한테 리스트를 전달할거야\n",
    "리스트의 합을 알려줘\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM 모델이 잘 이해하는 형태\n",
    "* Markdown\n",
    "    - 헤더 (#)\n",
    "        * 전달하고자 하는 내용을 구분\n",
    "    - 리스트\n",
    "        * 여러개의 요구사항을 전달할때, 모델이 더 잘 동작하게 해준다.\n",
    "EX)\n",
    "# OutPut\n",
    "- 너는 답변을 반드시 마크다운 코드로 작성해\n",
    "- 부가적인 설명은 달지마\n",
    "- 최대한 길게 작성해\n",
    "    - 표\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8 <br>\n",
    "EX) <br>\n",
    "\n",
    "| 왼쪽 정렬 | 가운데 정렬 | 오른쪽 정렬 |\n",
    "|:-----------|:------------:|------------:|\n",
    "| 데이터 1 | 데이터 2 | 데이터 3 |\n",
    "| 데이터 4 | 데이터 5 | 데이터 6 |\n",
    "\n",
    "* Json : key = value\n",
    "Ex) <br>\n",
    "    - 역할 = 강사\n",
    "    - 나이 = 20세\n",
    "\n",
    "* Symbol\n",
    "    - 특수문자등을 이용해서 전달하는 프롬프트의 중요 부분을 강조\n",
    "    - -,+,:,#,{},\"\"\"~\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 숫자의 합은 21입니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "다음의 합을 알려줘. 1,2,3,4,5,6\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
